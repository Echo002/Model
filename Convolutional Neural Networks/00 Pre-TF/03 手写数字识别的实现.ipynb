{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 数据集相关的常数设置\n",
    "INPUT_NODE = 784\n",
    "\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "LAYER1_NODE = 500  \n",
    "# 隐藏层的节点数（本结构只有一个隐藏层）\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "LRARNING_RATE_BASE = 0.8\n",
    "\n",
    "LRARNING_RATE_DECAY = 0.99  \n",
    "# 学习率的衰减率\n",
    "\n",
    "REGULARIZATION_RATE = 0.0001  \n",
    "# 正则化项在损失函数中的系数\n",
    "\n",
    "TRAINNING_STEPS = 30000  \n",
    "# 训练轮数\n",
    "\n",
    "MOVING_AVERAGE_DECAY = 0.99  \n",
    "# 滑动平均衰减率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助函数，计算神经网络的前向传播结果\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型过程\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "\n",
    "    # 生成隐藏层的参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "\n",
    "    # 生成输出层的数据\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "\n",
    "    # 计算当前参数前向传播的结果。这里给出的用于计算平均滑动的类为 NONE,所以函数不会使用参数的滑动平均值\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "\n",
    "    # 计算交叉熵                (需要将原文的语句做以下修改)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.arg_max(y_, 1), logits=y)\n",
    "    # 计算当前batch中所有样例的交叉熵的平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # 计算L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    # 计算模型的正则化损失\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "\n",
    "    # 总损失等于交叉熵损失和正则化损失的和\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    # 设置指数衰减的学习率\n",
    "    learning_rate = tf.train.exponential_decay(LRARNING_RATE_BASE, global_step, mnist.train.num_examples / BATCH_SIZE,\n",
    "                                               LRARNING_RATE_DECAY)  # 学习率衰减速度\n",
    "    # 优化损失函数，这里的损失函数包括交叉熵损失函数和L2损失函数\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # 一次进行反向传播参数更新网络中的 参数和参数的滑动平均值\n",
    "    # train_op=tf.group(train_step,variable_averages_op)     #此句话下面的两句话是等价操作\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "    correct_prediction = tf.equal(tf.arg_max(average_y, 1), tf.arg_max(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # 初始化会话并开始训练过程\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())  # 初始化所有的变量\n",
    "        validate_feed = {x: mnist.validation.images,\n",
    "                         y_: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "        # 迭代的训练神经网络\n",
    "        for i in range(TRAINNING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "                print('After %d training step(s),validation accuracy using average model is %g, test accuracy using average model is %g' % (i, validate_acc, test_acc))\n",
    "\n",
    "\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s),test accuracy using average model is %g\" % (TRAINNING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\DataSet\\MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting E:\\DataSet\\MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting E:\\DataSet\\MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\DataSet\\MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s),validation accuracy using average model is 0.0614, test accuracy using average model is 0.0505\n",
      "After 1000 training step(s),validation accuracy using average model is 0.9736, test accuracy using average model is 0.974\n",
      "After 2000 training step(s),validation accuracy using average model is 0.9788, test accuracy using average model is 0.9802\n",
      "After 3000 training step(s),validation accuracy using average model is 0.9808, test accuracy using average model is 0.9783\n",
      "After 4000 training step(s),validation accuracy using average model is 0.9818, test accuracy using average model is 0.9802\n",
      "After 5000 training step(s),validation accuracy using average model is 0.9834, test accuracy using average model is 0.9809\n",
      "After 6000 training step(s),validation accuracy using average model is 0.982, test accuracy using average model is 0.9815\n",
      "After 7000 training step(s),validation accuracy using average model is 0.9838, test accuracy using average model is 0.9821\n",
      "After 8000 training step(s),validation accuracy using average model is 0.9858, test accuracy using average model is 0.9823\n",
      "After 9000 training step(s),validation accuracy using average model is 0.984, test accuracy using average model is 0.9826\n",
      "After 10000 training step(s),validation accuracy using average model is 0.9826, test accuracy using average model is 0.9825\n",
      "After 11000 training step(s),validation accuracy using average model is 0.985, test accuracy using average model is 0.9822\n",
      "After 12000 training step(s),validation accuracy using average model is 0.9844, test accuracy using average model is 0.9832\n",
      "After 13000 training step(s),validation accuracy using average model is 0.9832, test accuracy using average model is 0.9829\n",
      "After 14000 training step(s),validation accuracy using average model is 0.985, test accuracy using average model is 0.9836\n",
      "After 15000 training step(s),validation accuracy using average model is 0.9844, test accuracy using average model is 0.9835\n",
      "After 16000 training step(s),validation accuracy using average model is 0.984, test accuracy using average model is 0.9835\n",
      "After 17000 training step(s),validation accuracy using average model is 0.9844, test accuracy using average model is 0.9828\n",
      "After 18000 training step(s),validation accuracy using average model is 0.9854, test accuracy using average model is 0.9836\n",
      "After 19000 training step(s),validation accuracy using average model is 0.9838, test accuracy using average model is 0.9834\n",
      "After 20000 training step(s),validation accuracy using average model is 0.985, test accuracy using average model is 0.9826\n",
      "After 21000 training step(s),validation accuracy using average model is 0.9844, test accuracy using average model is 0.983\n",
      "After 22000 training step(s),validation accuracy using average model is 0.9846, test accuracy using average model is 0.9831\n",
      "After 23000 training step(s),validation accuracy using average model is 0.9856, test accuracy using average model is 0.9834\n",
      "After 24000 training step(s),validation accuracy using average model is 0.9846, test accuracy using average model is 0.9829\n",
      "After 25000 training step(s),validation accuracy using average model is 0.9836, test accuracy using average model is 0.9829\n",
      "After 26000 training step(s),validation accuracy using average model is 0.9866, test accuracy using average model is 0.9839\n",
      "After 27000 training step(s),validation accuracy using average model is 0.9852, test accuracy using average model is 0.9833\n",
      "After 28000 training step(s),validation accuracy using average model is 0.9852, test accuracy using average model is 0.9832\n",
      "After 29000 training step(s),validation accuracy using average model is 0.9844, test accuracy using average model is 0.9837\n",
      "After 30000 training step(s),test accuracy using average model is 0.9838\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Echo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3273: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 主程序入口\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"E:\\DataSet\\MNIST\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
