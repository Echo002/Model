{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人臉辨識 - 轉換、對齊、裁剪、特徵擷取與比對\n",
    "\n",
    "人臉辨識大致可分成四個主要的步驟:\n",
    "1. 人臉偵測\n",
    "2. 人臉轉換、對齊與裁剪\n",
    "3. 人臉特徵擷取\n",
    "4. 人臉特徵比對\n",
    "\n",
    "這個Jupyter Notebook展示了一個四個步驟整合起來的結果。但要進行這個Jupyter notebook之前, 要先完成以下兩個程序：\n",
    "\n",
    "* [[01-face-detect-align-and-crop](https://github.com/erhwenkuo/face-recognition/blob/master/01-face-detect-align-and-crop.ipynb)] - 介紹如何進行\"人臉偵測\"、\"對齊\" & \"裁剪\"。\n",
    "\n",
    "\n",
    "* [[02-face-embedding-and-recognition-classifier](https://github.com/erhwenkuo/face-recognition/blob/master/02-face-embedding-and-recognition-classifier.ipynb)] - 介紹如何進行人臉特徵擷取(FaceNet) & 訓練人臉分類器。\n",
    "\n",
    "\n",
    "![face-recognition](http://devfun-lab.com/en/wdvfnp/wp-content/uploads/2017/09/h3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face-recognition 專案說明\n",
    "\n",
    "[face-recognition](https://github.com/erhwenkuo/face-recognition)包含了使用MTCNN、FaceNet以及SVM(Suport Vector Machine)三種演算法來進行人臉辨識的整個循環。\n",
    "\n",
    "### 安裝\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/erhwenkuo/face-recognition.git\n",
    "cd face-recognition\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料集說明\n",
    "\n",
    "LFW資料集是一個常見的人臉資料集，歷史非常悠久。LFW資料集中收錄了5749位公眾人物的人臉影像，總共有超過一萬三千多張影像檔案。但大部份公眾人物的影像都只有一張，只有1680位有超過一張照片，而極少數有超過10張照片。\n",
    "\n",
    "資料集的網站: http://vis-www.cs.umass.edu/lfw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 專案的檔案路徑佈局\n",
    "\n",
    "1. 使用Git從[erhwenkuo/face-recognition](https://github.com/erhwenkuo/face-recognition.git)下載整個專案源碼\n",
    "2. 在`face-recognition`的目錄裡產生二個子目錄`data`與`model`\n",
    "3. 從[Labeled Faces in the Wild資料集官網]點撃[All images as gzipped tar file](http://vis-www.cs.umass.edu/lfw/lfw.tgz)來下載`lfw.tgz`。\n",
    "4. 解壓縮`lfw.tgz`到`face-recognition/data/`的目錄下\n",
    "5. 執行`01-face-detect-align-and-crop.ipynb`來進行臉部偵測、對齊 & 裁剪\n",
    "6. 下載Facenet模型檔[20170511-185253.zip(168M)](https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk)並解壓縮到\"model/facenet\"的目錄下。\n",
    "7. 在\"model\"的目錄下產生一個子目錄\"svm\"來存放\"人臉分類器\"的模型。\n",
    "8. 執行`02-face-embedding-and-recognition-classifier.ipynb`來進行人臉特徵擷取(FaceNet) & 訓練人臉分類器\n",
    "9. 在\"data\"的目錄下產生一個子目錄\"test\"來存放\"人臉辨識\"用的測試圖像\n",
    "\n",
    "\n",
    "最後你的目錄結構看起來像這樣: (這裡只列出來在這個範例會用到的相關檔案與目錄)\n",
    "```\n",
    "face-recognition/\n",
    "├── 01-face-detect-align-and-crop.ipynb\n",
    "├── 02-face-embedding-and-recognition-classifier.ipynb\n",
    "├── 03-face-classification.ipynb\n",
    "├── detect_face.py\n",
    "├── facenet.py\n",
    "├── visualization_utils.py\n",
    "├── model/\n",
    "│   ├── svm/                                <--- 人臉分類器(svm)的模型\n",
    "│   │   └── lfw_svm_classifier.pkl\n",
    "│   ├── mtcnn/\n",
    "│   │   ├── det1.npy\n",
    "│   │   ├── det2.npy\n",
    "│   │   └── det3.npy\n",
    "│   └── facenet/                            <--- Facenet的模型\n",
    "│       └── 20170512-110547/\n",
    "│          ├── 20170512-110547.pb\n",
    "│          ├── model-20170512-110547.ckpt-250000.data-00000-of-00001\n",
    "│          ├── model-20170512-110547.ckpt-250000.index\n",
    "│          └── model-20170512-110547.meta\n",
    "└── data/\n",
    "    ├── test/\n",
    "    ├── lfw/\n",
    "    │   ├── Aaron_Eckhart/     \n",
    "    │   │   └── Aaron_Eckhart_0001.jpg\n",
    "    │   ├── ...\n",
    "    │   └── Zydrunas_Ilgauskas/\n",
    "    │       └── Zydrunas_Ilgauskas_0001.jpg\n",
    "    └── lfw_crops/                          <--- 經過偵測、對齊 & 裁剪後的人臉圖像\n",
    "        ├── Aaron_Eckhart/     \n",
    "        │   └── Aaron_Eckhart_0001.png\n",
    "        ├── ...\n",
    "        └── Zydrunas_Ilgauskas/\n",
    "            └── Zydrunas_Ilgauskas_0001.png    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1. 載入相關函式庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:22.894038Z",
     "start_time": "2019-04-06T13:55:20.738807Z"
    }
   },
   "outputs": [],
   "source": [
    "# 屏蔽Jupyter的warning訊息\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utilities相關函式庫\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy import misc\n",
    "from scipy.spatial import distance # 用來計算歐幾里德距離 (euclidean)\n",
    "\n",
    "# 圖像處理相關函式庫\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 多維向量處理相關函式庫\n",
    "import numpy as np\n",
    "\n",
    "# 深度學習相關函式庫\n",
    "import tensorflow as tf\n",
    "\n",
    "# 機械學習\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# 模型序列化函式庫\n",
    "import pickle\n",
    "\n",
    "# 專案相關函式庫\n",
    "import facenet\n",
    "import detect_face\n",
    "import visualization_utils as vis_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2. 設定相關設定與參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:24.696599Z",
     "start_time": "2019-04-06T13:55:24.690615Z"
    }
   },
   "outputs": [],
   "source": [
    "# 專案的根目錄路徑\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# 訓練/驗證用的資料目錄\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# 模型的資料目錄\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"model\")\n",
    "\n",
    "# MTCNN的模型\n",
    "MTCNN_MODEL_PATH = os.path.join(MODEL_PATH, \"mtcnn\")\n",
    "\n",
    "# FaceNet的模型\n",
    "FACENET_MODEL_PATH = os.path.join(MODEL_PATH, \"facenet\",\"20170512-110547\",\"20170512-110547.pb\")\n",
    "\n",
    "# Classifier的模型\n",
    "SVM_MODEL_PATH = os.path.join(MODEL_PATH, \"svm\", \"lfw_svm_classifier.pkl\")\n",
    "\n",
    "# 訓練/驗證用的圖像資料目錄\n",
    "IMG_IN_PATH = os.path.join(DATA_PATH, \"lfw\")\n",
    "\n",
    "# 訓練/驗證用的圖像資料目錄\n",
    "IMG_OUT_PATH = os.path.join(DATA_PATH, \"lfw_crops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3. 載入人臉Facenet處理過的相關的人臉embedding資料\n",
    "\n",
    "轉換每張人臉的圖像成為Facenet的人臉特徵向量(128 bytes)表示。\n",
    "\n",
    "函式: `facenet.get_dataset`\n",
    "```\n",
    "參數:\n",
    "    paths (string): 圖像資料集的檔案路徑\n",
    "    has_class_directories (bool): 是否使用子目錄名作為人臉的identity (預設為True)\n",
    "    path_expanduser (bool): 是否把path中包含的\"~\"和\"~user\"轉換成在作業系統下的用戶根目錄 (預設為False)\n",
    "回傳:\n",
    "    dataset (list[ImageClass])： 人臉類別(ImageClass)的列表與圖像路徑\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:25.678265Z",
     "start_time": "2019-04-06T13:55:25.661312Z"
    }
   },
   "outputs": [],
   "source": [
    "# 反序列化相關可重覆使用的資料\n",
    "# \"人臉embedding\"的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_features.pkl'), 'rb') as emb_features_file:\n",
    "    emb_features =pickle.load(emb_features_file)\n",
    "\n",
    "# \"人臉embedding\"所對應的標籤(label)的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels.pkl'), 'rb') as emb_lables_file:\n",
    "    emb_labels =pickle.load(emb_lables_file)\n",
    "\n",
    "# \"標籤(label)對應到人臉名稱的字典的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels_dict.pkl'), 'rb') as emb_lables_dict_file:\n",
    "    emb_labels_dict =pickle.load(emb_lables_dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於lfw的人臉資料庫的人臉圖像太少, 因此經過過濾之後我們從lfw的人臉資料庫中選出423個人臉的類別(每個類別都至少有5張的圖像以上)來做為人臉辨識的目標範例資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:26.795300Z",
     "start_time": "2019-04-06T13:55:26.744438Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_dict = {} # key 是label, value是embedding list\n",
    "for feature,label in zip(emb_features, emb_labels):\n",
    "    # 檢查key有沒有存在\n",
    "    if label in emb_dict:\n",
    "        emb_dict[label].append(feature)\n",
    "    else:\n",
    "        emb_dict[label] = [feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:27.426946Z",
     "start_time": "2019-04-06T13:55:27.418940Z"
    }
   },
   "outputs": [],
   "source": [
    "# 計算兩個人臉特徵（Facenet Embedding 128 bytes vector)的歐式距離\n",
    "def calc_dist(face1_emb, face2_emb):    \n",
    "    return distance.euclidean(face1_emb, face2_emb)\n",
    "\n",
    "face_distance_threshold = 1.1\n",
    "\n",
    "# 計算一個人臉的embedding是不是歸屬某一個人\n",
    "# 根據Google Facenet的論文, 透過計算兩個人臉embedding的歐氏距離\n",
    "# 0: 代表為同一個人臉 , threshold <1.1 代表兩個人臉非常相似 \n",
    "def is_same_person(face_emb, face_label, threshold=1.1):\n",
    "    emb_distances = []\n",
    "    emb_features = emb_dict[face_label]\n",
    "    for i in range(len(emb_features)):\n",
    "        emb_distances.append(calc_dist(face_emb, emb_features[i]))\n",
    "    \n",
    "    # 取得平均值\n",
    "    if np.mean(emb_distances) > threshold: # threshold <1.1 代表兩個人臉非常相似 \n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4. 載入預訓練MTCNN的模型來偵測人臉位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 設定人臉偵測模型所需的相關參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:29.162151Z",
     "start_time": "2019-04-06T13:55:29.155173Z"
    }
   },
   "outputs": [],
   "source": [
    "minsize = 40  # 最小的臉部的大小\n",
    "threshold = [0.6, 0.7, 0.7]  # 三個網絡(P-Net, R-Net, O-Net)的閥值\n",
    "factor = 0.709  # scale factor\n",
    "\n",
    "margin = 44 # 在裁剪人臉時的邊框margin\n",
    "image_size = 182 # 160 + 22\n",
    "\n",
    "batch_size = 1000\n",
    "input_image_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:30.095333Z",
     "start_time": "2019-04-06T13:55:29.707370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x1abd43d8da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 創建Tensorflow Graph物件\n",
    "tf_g = tf.Graph().as_default()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "\n",
    "# 創建Tensorflow Session物件\n",
    "tf_sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "\n",
    "# 把這個Session設成預設的session\n",
    "tf_sess.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:32.672607Z",
     "start_time": "2019-04-06T13:55:30.643900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 載入MTCNN模型 (偵測人臉位置)\n",
    "pnet, rnet, onet = detect_face.create_mtcnn(tf_sess, MTCNN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5. 載入預訓練FaceNet的模型來擷取人臉特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:39.193985Z",
     "start_time": "2019-04-06T13:55:32.674430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature extraction model\n",
      "Model filename: E:\\Code\\Model\\Convolutional Neural Networks\\MTCNN-keras\\face-recognition\\model\\facenet\\20170512-110547\\20170512-110547.pb\n",
      "Face embedding size:  128\n"
     ]
    }
   ],
   "source": [
    "# 載入Facenet模型\n",
    "print('Loading feature extraction model')\n",
    "modeldir =  FACENET_MODEL_PATH #'/..Path to Pre-trained model../20170512-110547/20170512-110547.pb'\n",
    "facenet.load_model(modeldir)\n",
    "\n",
    "# 取得模型的輸入與輸出的佔位符\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "# 打印\"人臉特徵向量\"的向量大小\n",
    "print(\"Face embedding size: \", embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6. 載入預訓練SVM分類器模型來進行人臉識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T13:55:41.955183Z",
     "start_time": "2019-04-06T13:55:41.945210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load classifier file-> E:\\Code\\Model\\Convolutional Neural Networks\\MTCNN-keras\\face-recognition\\model\\svm\\lfw_svm_classifier.pkl\n",
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# 載入SVM分類器模型\n",
    "classifier_filename = SVM_MODEL_PATH\n",
    "\n",
    "with open(classifier_filename, 'rb') as svm_model_file:\n",
    "    (face_svc_classifier, face_identity_names) = pickle.load(svm_model_file)\n",
    "    HumanNames = face_identity_names    #訓練時的人臉的身份\n",
    "    \n",
    "    print('load classifier file-> %s' % classifier_filename)\n",
    "    print(face_svc_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7. 進行人臉識別\n",
    "\n",
    "從網路上找一個人臉圖像來進行測試:\n",
    "\n",
    "圖像URL: https://xk.usembassy.gov/wp-content/uploads/sites/133/2016/09/Four_Presidents-1.jpg\n",
    "\n",
    "把這個圖像下載下來到專案的測試目錄下: \"__data/test/Four_Presidents-1.jpg__\"\n",
    "\n",
    "![us-presidents](https://xk.usembassy.gov/wp-content/uploads/sites/133/2016/09/Four_Presidents-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-06T13:55:48.142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Recognition!\n"
     ]
    }
   ],
   "source": [
    "print('Start Recognition!')\n",
    "\n",
    "face_input = \"data/test/Four_Presidents-1.jpg\"\n",
    "\n",
    "find_results = []\n",
    "frame = cv2.imread(face_input) # 讀入圖像\n",
    "draw = frame.copy() # 複製原圖像\n",
    "\n",
    "frame = frame[:,:,::-1] # 把BGR轉換成RGB\n",
    "# 步驟 #1.偵測人臉位置\n",
    "# 偵測人臉的邊界框\n",
    "bounding_boxes, _ = detect_face.detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\n",
    "nrof_faces = bounding_boxes.shape[0] # 被偵測到的臉部總數\n",
    "if nrof_faces > 0: # 如果有偵測到人臉\n",
    "    # 每一個 bounding_box包括了（x1,y1,x2,y2,confidence score)：\n",
    "    # 　　左上角座標 (x1,y1)\n",
    "    #     右下角座標 (x2,y2)\n",
    "    #     信心分數 confidence score\n",
    "    det = bounding_boxes[:, 0:4].astype(int) # 取出邊界框座標\n",
    "    img_size = np.asarray(frame.shape)[0:2] # 原圖像大小 (height, width)\n",
    "    \n",
    "    print(\"Image: \", img_size)\n",
    "    \n",
    "    # 人臉圖像前處理的暫存\n",
    "    cropped = []\n",
    "    scaled = []\n",
    "    scaled_reshape = []\n",
    "    bb = np.zeros((nrof_faces,4), dtype=np.int32)\n",
    "    \n",
    "    # 步驟 #2.擷取人臉特徵\n",
    "    for i in range(nrof_faces):\n",
    "        print(\"faces#{}\".format(i))\n",
    "        emb_array = np.zeros((1, embedding_size))\n",
    "\n",
    "        x1 = bb[i][0] = det[i][0]\n",
    "        y1 = bb[i][1] = det[i][1]\n",
    "        x2 = bb[i][2] = det[i][2]\n",
    "        y2 = bb[i][3] = det[i][3]\n",
    "        \n",
    "        print('({}, {}) : ({}, {})'.format(x1,y1,x2,y2))\n",
    "        # inner exception\n",
    "        if bb[i][0] <= 0 or bb[i][1] <= 0 or bb[i][2] >= len(frame[0]) or bb[i][3] >= len(frame):\n",
    "            print('face is out of range!')\n",
    "            continue\n",
    "        \n",
    "        # **人臉圖像的前處理 **\n",
    "            \n",
    "        # 根據邊界框的座標來進行人臉的裁剪\n",
    "        cropped.append(frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :])\n",
    "        cropped[i] = facenet.flip(cropped[i], False)\n",
    "        scaled.append(misc.imresize(cropped[i], (image_size, image_size), interp='bilinear'))\n",
    "        scaled[i] = cv2.resize(scaled[i], (input_image_size,input_image_size),\n",
    "                               interpolation=cv2.INTER_CUBIC)\n",
    "        scaled[i] = facenet.prewhiten(scaled[i])\n",
    "        scaled_reshape.append(scaled[i].reshape(-1,input_image_size,input_image_size,3))       \n",
    "        feed_dict = {images_placeholder: scaled_reshape[i], phase_train_placeholder: False}\n",
    "        \n",
    "        # 進行臉部特徵擷取\n",
    "        emb_array[0, :] = tf_sess.run(embeddings, feed_dict=feed_dict)\n",
    "        \n",
    "        # 步驟 #3.進行人臉識別分類\n",
    "        face_id_idx = face_svc_classifier.predict(emb_array)   \n",
    "            \n",
    "        if is_same_person(emb_array, int(face_id_idx), 1.1):            \n",
    "            face_id_name = HumanNames[int(face_id_idx)] # 取出人臉的名字\n",
    "            bb_color = vis_utils.STANDARD_COLORS[i] # 給予不同的顏色\n",
    "            bb_fontcolor = 'black'\n",
    "        else:\n",
    "            face_id_name = 'Unknown'\n",
    "            bb_color = 'BlueViolet' # 給予紅色\n",
    "            bb_fontcolor = 'white'\n",
    "        \n",
    "        # 進行視覺化的展現\n",
    "        vis_utils.draw_bounding_box_on_image_array(draw,y1,x1,y2,x2,\n",
    "                                                   color=bb_color,\n",
    "                                                   thickness=2,\n",
    "                                                   display_str_list=[face_id_name],\n",
    "                                                   fontname='calibrib.ttf',         # <-- 替換不同的字型\n",
    "                                                   fontsize=15,                     # <-- 根據圖像大小設定字型大小\n",
    "                                                   fontcolor=bb_fontcolor,\n",
    "                                                   use_normalized_coordinates=False)\n",
    "else:\n",
    "    print('Unable to align')\n",
    "\n",
    "print('Detected_FaceNum: %d' % nrof_faces)\n",
    "\n",
    "# 設定展示的大小\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# 展示偵測出來的結果\n",
    "plt.imshow(draw[:,:,::-1]) # 轉換成RGB來給matplotlib展示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "從以上的結果來看, 我們辨識出5張人臉。其中\"Barack Obama(歐巴馬)\"並不在我們從lfw的人臉資料庫中選出423個人臉的類別裡頭。所以從驗證結果來看, 這個人臉的識別效果還不錯。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參考:\n",
    "* Facenet-Github (davidsandberg/facenet) - https://github.com/davidsandberg/facenet\n",
    "* OpenFace-Github (cmusatyalab/openface) - https://github.com/cmusatyalab/openface\n",
    "* Multi-task Cascaded Convolutional Networks論文 - https://arxiv.org/abs/1604.02878\n",
    "* FaceNet: A Unified Embedding for Face Recognition and Clustering論文 - https://arxiv.org/abs/1503.03832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
